/*
ID 89135726
-- ПРИНЦИП РАБОТЫ --

Строим индекс, представляющий собой map, где для каждого слова учитываем сколько оно в каком документе встречалось(тоже через map)

Потом идём по каждому запросу, ищем слово в индексе, смотрим количество вхождений в документах. Суммируем и получаем релевантность каждого документа

После выполняется сортировка документов по релевантности

-- ДОКАЗАТЕЛЬСТВО КОРРЕКТНОСТИ --

Алгоритм обрабатывает каждый документ и строит индекс

Затем алгоритм обрабатывает каждый запрос и находит документы, содержащие все слова из запроса.

Для каждого найденного документа вычисляется релевантность путем суммирования количества вхождений всех слов запроса в документ.

После этого документы сортируются по убыванию релевантности и выбираются пять наиболее релевантных документов.

Если мы имеем для каждого слова количество вхождений в каждый из документов,

То суммируя эти значения с помощью вспомогательной мапы,

Получим как раз искомое значение релевантности для каждого документа в случае какой-либо конкретной строки.

-- ВРЕМЕННАЯ СЛОЖНОСТЬ --

Данный алгоритм имеет временную сложность O(n+ m + m*log(m)), где n - количество запросов, m - количество документов.

Обработка каждого слова в каждом документе - n раз. Строки в каждом документе разбиваются на слова,

и каждое слово обрабатывается только один раз, так что количество итераций зависит от общего количества слов в документах m.

Таким образом, временная сложность O(n*m*log(m)), где m*log(m) - сложность сортировки слиянием в sort.Slice.

-- ПРОСТРАНСТВЕННАЯ СЛОЖНОСТЬ --

index - мапа, которая хранит информацию о количестве вхождений каждого слова в каждом документе.

Пространственная сложность этой мапы зависит от общего количества уникальных слов и документов во входных данных.

При хранении слова идентификатора документа в каждом слове и их количества сложность будет O(kw * kd), где kw - количество уникальных слов, kd - количество документов.

relevance - мапа, которая хранит суммарную релевантность каждого документа для данного запроса.

Пространственная сложность этой мапы зависит от количества документов и их релевантности для запроса.

Сложность будет O(kd), где kd - количество документов.

seenWords - мапа, которая отслеживает уже учтенные слова в запросе для избежания повторных вычислений.

Пространственная сложность этой карты зависит от количества уникальных слов в запросе.

Сложность будет O(kw), где kw - количество уникальных слов в запросе.



sorted - слайс, который хранит отсортированные документы по релевантности и идентификатору документа.

Пространственная сложность этого слайса будет O(kd), где kd - количество документов.



Таким образом, общая пространственная сложность алгоритма будет O(kw * kd),

где kw - количество уникальных слов в запросе, kd - количество документов, так как наиболее объемная структура данных - мапа index.



*/

package A

import (
	"bufio"

	"fmt"

	"os"

	"sort"

	"strconv"

	"strings"
)

const relevantDocs = 5

type Doc struct {
	id int

	rel int
}

func main() {

	s := bufio.NewScanner(os.Stdin)

	buf := make([]byte, 0, 4096)

	s.Buffer(buf, 1000*10000+1000*10000)

	s.Scan()

	nd, _ := strconv.Atoi(s.Text())

	index := make(map[string]map[int]int)

	n := 1

	for n <= nd && s.Scan() {

		doc := s.Text()

		for _, w := range strings.Split(doc, " ") {

			_, ok := index[w]

			if !ok {

				index[w] = map[int]int{n: 0}

			}

			index[w][n]++

		}

		n++

	}

	s.Scan()

	nr, _ := strconv.Atoi(s.Text())

	var res strings.Builder

	for nr > 0 && s.Scan() {

		sorted := make([]*Doc, 0, nd)

		relevance := make(map[int]int)

		seenWords := make(map[string]struct{})

		req := s.Text()

		for _, m := range strings.Split(req, " ") {

			if _, ok := seenWords[m]; ok {

				continue

			}

			if docCnts, ok := index[m]; ok {

				for k, v := range docCnts {

					relevance[k] += v

				}

				seenWords[m] = struct{}{}

			}

		}

		for n, r := range relevance {

			sorted = append(sorted, &Doc{id: n, rel: r})

		}

		sort.Slice(sorted, func(i, j int) bool {

			if sorted[i].rel > sorted[j].rel {

				return true

			}

			if sorted[i].rel < sorted[j].rel {

				return false

			}

			return sorted[i].id < sorted[j].id

		})

		for i, d := range sorted {

			if i >= relevantDocs {

				break

			}

			res.WriteString(strconv.Itoa(d.id))

			if i < relevantDocs-1 && i != len(sorted)-1 {

				res.WriteString(" ")

			}

		}

		if nr >= 2 {

			res.WriteString("\n")

		}

		nr--

	}

	fmt.Print(res.String())

}
